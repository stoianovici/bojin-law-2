# [OPS-002] Legacy import stuck at 8k docs

| Field           | Value                |
| --------------- | -------------------- |
| **Status**      | Resolved             |
| **Type**        | Performance          |
| **Priority**    | P1-High              |
| **Created**     | 2025-12-08           |
| **Sessions**    | 5                    |
| **Last Active** | 2025-12-09 07:35 UTC |

## Description

Legacy document import process stalls/fails when processing approximately 8,000 documents. The system becomes unresponsive or times out when trying to load and process large document batches.

## Reproduction Steps

1. Initiate legacy import with ~8,000+ documents
2. Observe import process stalling during batch loading phase
3. get-batch endpoint becomes slow/unresponsive

## Root Cause

**PRIMARY (Session 2):** The `/api/get-batch` endpoint in `apps/legacy-import/src/app/api/get-batch/route.ts` had NO pagination - it fetched ALL documents for a user's batches in a single query. At 8K docs, this causes memory exhaustion and payload too large.

**SECONDARY (Session 2):** Missing composite database indexes on `(sessionId, batchId)` causing slow queries.

**TERTIARY (Session 3 - CRITICAL):** The extraction process itself stopped at ~8K documents due to:

1. **Memory exhaustion**: `extractFromPSTFile()` loaded ALL document Buffers into memory at once. With 8K+ PDFs (100KB-10MB each), this could require 1-10GB of RAM.
2. **Sequential processing**: Each document was uploaded to R2 and had text extracted (~1-2 seconds per doc). 8K docs = 2-4 hours of processing.
3. **Render request timeout**: Render web services have a 10-minute timeout. The extraction request was killed after 10 minutes, leaving the process incomplete at ~8K docs.

## Fix Applied

**Fix 1: Remove extractedText from batch query (reduce payload ~90%)**

- File: `apps/legacy-import/src/app/api/get-batch/route.ts`
- Removed `extractedText: true` from select - this large TEXT field was being loaded for all 8K docs
- extractedText is now loaded lazily via the document-url endpoint when a document is selected

**Fix 2: Add extractedText to document-url endpoint**

- File: `apps/legacy-import/src/app/api/document-url/route.ts`
- Added `extractedText` to the select and response
- Frontend now fetches extractedText per-document when needed

**Fix 3: Update frontend for lazy loading**

- File: `apps/legacy-import/src/stores/documentStore.ts` - Added `extractedTexts` cache and `setExtractedText` action
- File: `apps/legacy-import/src/components/Categorization/CategorizationWorkspace.tsx` - Fetch and cache extractedText with document URL

**Fix 4: Add pagination to get-batch endpoint**

- File: `apps/legacy-import/src/app/api/get-batch/route.ts`
- Added `page` and `pageSize` query params (default 100, max 500)
- Added `skip` and `take` to Prisma query
- Added `pagination` object to response with page info

**Fix 5: Add composite indexes for query performance**

- File: `packages/database/prisma/schema.prisma`
- Added `@@index([sessionId, batchId])` - used in get-batch query
- Added `@@index([sessionId, status])` - used in analysis queries

**Fix 6 (Session 3): Resumable batch extraction**

- File: `packages/database/prisma/schema.prisma`
  - Added `extractionProgress` JSON field to track: `{totalInPst, extractedCount, isComplete}`

- File: `apps/legacy-import/src/services/pst-parser.service.ts`
  - Added `BatchExtractionOptions` interface with `skip` and `take` parameters
  - Added `countDocumentsInPST()` - fast scan to count total docs without loading content
  - Modified `processFolder()` to support skip/take for resumable extraction
  - Modified `extractFromPSTFile()` to accept batch options

- File: `apps/legacy-import/src/app/api/extract-documents/route.ts`
  - First call: counts total documents in PST, saves to `extractionProgress`
  - Subsequent calls: resumes from where it left off (skip already extracted docs)
  - Processes ~500 docs per batch (fits within 10-minute timeout)
  - Returns progress: `{totalInPst, extractedCount, isComplete, remainingCount}`

- File: `apps/legacy-import/src/app/page.tsx`
  - Updated `ExtractStep` component to support batch extraction with "Continue" button
  - Added `ExtractionIncompleteBanner` component shown in categorize step when extraction incomplete
  - Shows progress bar with extracted/total counts
  - Allows users to continue extraction or proceed with partial data

## Session Log

- [2025-12-08 19:45] Issue created. Initial triage identified critical pagination issue in get-batch endpoint. The endpoint loads ALL documents without pagination, and includes the large `extractedText` field unnecessarily.
- [2025-12-08 20:00] Session 2 started. Continuing from: New. Beginning implementation of pagination fix.
- [2025-12-08 20:15] Session 2 - Implemented 5 fixes: (1) Removed extractedText from batch query, (2) Added extractedText to document-url for lazy loading, (3) Updated frontend store and component for lazy text loading, (4) Added pagination with page/pageSize params, (5) Added composite indexes. Ready for deployment and verification.
- [2025-12-08] Session 3 started. Problem persists - extraction stopping at ~8K docs.
- [2025-12-08] Session 3 - Root cause found: extraction loads ALL documents into memory and processes sequentially. With 8K+ docs, this exceeds Render's 10-minute request timeout.
- [2025-12-08] Session 3 - Implemented resumable batch extraction: PST parser now supports skip/take, API tracks progress in DB, frontend shows "Continue extraction" button. Extracts ~500 docs per batch to stay under timeout.
- [2025-12-08] Session 4 - 502 errors on extract-documents. Root cause: `countDocumentsInPST()` was calling `getAttachment()` for every attachment to check file extension, which is extremely slow for 8K+ docs (causes Render timeout). Fixed by using fast estimation that just counts `numberOfAttachments` without loading attachment data. Also added `extractionProgress` field to legacy-import Prisma schema (was missing).
- [2025-12-09] Session 5 started. "Failed to get batch assignment" and "Failed to fetch dashboard" errors.
- [2025-12-09] Session 5 - Root cause: The `extraction_progress` column was missing from production database. Schema had the field but migration was never run. All API endpoints querying LegacyImportSession were failing with "The column legacy_import_sessions.extraction_progress does not exist".
- [2025-12-09] Session 5 - Fix: Created temporary migration endpoint, deployed, ran `ALTER TABLE legacy_import_sessions ADD COLUMN IF NOT EXISTS extraction_progress JSONB`. All endpoints now working. 8000 documents visible in 120+ monthly batches (2013-03 to 2025-11).
- [2025-12-09] Session 5 - **RESOLVED**. Categorization page and Dashboard now load successfully.

## Files Involved

- `apps/legacy-import/src/app/api/get-batch/route.ts` - **FIXED** - Added pagination, removed extractedText
- `apps/legacy-import/src/app/api/document-url/route.ts` - **FIXED** - Added extractedText to response
- `apps/legacy-import/src/stores/documentStore.ts` - **FIXED** - Added extractedTexts cache
- `apps/legacy-import/src/components/Categorization/CategorizationWorkspace.tsx` - **FIXED** - Lazy load extractedText
- `packages/database/prisma/schema.prisma` - **FIXED** - Added composite indexes + extractionProgress field
- `apps/legacy-import/src/services/pst-parser.service.ts` - **FIXED** - Added skip/take batch extraction + countDocumentsInPST
- `apps/legacy-import/src/app/api/extract-documents/route.ts` - **FIXED** - Resumable batch extraction with progress tracking
- `apps/legacy-import/src/app/page.tsx` - **FIXED** - ExtractStep with batch UI + ExtractionIncompleteBanner
- `apps/legacy-import/src/app/api/analyze-documents/route.ts` - Batch size limited to 100 (future optimization)
- `apps/legacy-import/src/services/ai-document-analyzer.ts` - BATCH_SIZE = 25 (future optimization)
